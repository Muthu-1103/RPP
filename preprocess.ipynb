{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_xml(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    glucose_levels = []\n",
    "    basal_insulin = []\n",
    "    bolus_insulin = []\n",
    "    carbs = []\n",
    "    timestamps = []\n",
    "\n",
    "    # Extract glucose levels\n",
    "    for glucose_event in root.findall(\".//glucose_level/event\"):\n",
    "        ts = glucose_event.get('ts')\n",
    "        value = float(glucose_event.get('value'))\n",
    "        glucose_levels.append((ts, value))\n",
    "\n",
    "    # Extract basal insulin\n",
    "    for basal_event in root.findall(\".//basal/event\"):\n",
    "        ts = basal_event.get('ts')\n",
    "        value = float(basal_event.get('value'))\n",
    "        basal_insulin.append((ts, value))\n",
    "\n",
    "    # Extract bolus insulin\n",
    "    for bolus_event in root.findall(\".//bolus/event\"):\n",
    "        ts = bolus_event.get('ts_begin')\n",
    "        dose = float(bolus_event.get('dose'))\n",
    "        bolus_insulin.append((ts, dose))\n",
    "\n",
    "    # Extract meal data\n",
    "    for meal_event in root.findall(\".//meal/event\"):\n",
    "        ts = meal_event.get('ts')\n",
    "        carbs_value = float(meal_event.get('carbs'))\n",
    "        carbs.append((ts, carbs_value))\n",
    "\n",
    "    # Combine all data into a DataFrame\n",
    "    data = []\n",
    "    for ts, glucose in glucose_levels:\n",
    "        basal = next((value for t, value in basal_insulin if t == ts), 0)\n",
    "        bolus = next((dose for t, dose in bolus_insulin if t == ts), 0)\n",
    "        meal = next((carbs_value for t, carbs_value in carbs if t == ts), 0)\n",
    "        data.append((ts, glucose, basal, bolus, meal))\n",
    "\n",
    "    df = pd.DataFrame(data, columns=['timestamp', 'glucose', 'basal_insulin', 'bolus_insulin', 'carbs'])\n",
    "    \n",
    "    # Specify the correct format for parsing the timestamp\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], format='%d-%m-%Y %H:%M:%S')\n",
    "    \n",
    "    # Set timestamp as index\n",
    "    df.set_index('timestamp', inplace=True)\n",
    "    \n",
    "    # Handle missing data\n",
    "    df = df.interpolate(method='time')\n",
    "    \n",
    "    # Normalize the data\n",
    "    scaler = StandardScaler()\n",
    "    df[['glucose', 'basal_insulin', 'bolus_insulin', 'carbs']] = scaler.fit_transform(df[['glucose', 'basal_insulin', 'bolus_insulin', 'carbs']])\n",
    "    \n",
    "    # Feature extraction\n",
    "    df['moving_avg'] = df['glucose'].rolling(window=5).mean()\n",
    "    df['rate_of_change'] = df['glucose'].diff()\n",
    "    df['lag_1'] = df['glucose'].shift(1)\n",
    "    df['lag_2'] = df['glucose'].shift(2)\n",
    "    \n",
    "    # Drop NaN values created by feature extraction\n",
    "    df = df.dropna()\n",
    "\n",
    "    return df, scaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_multiple_xml(files):\n",
    "    all_data = []\n",
    "    for file in files:\n",
    "        data, scaler = parse_xml(file)\n",
    "        all_data.append(data)\n",
    "    combined_data = pd.concat(all_data, ignore_index=True)\n",
    "    return combined_data, scaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    glucose  basal_insulin  bolus_insulin  carbs  moving_avg  rate_of_change  \\\n",
      "0  1.240196            0.0            0.0    0.0    1.335676       -0.074593   \n",
      "1  1.135766            0.0            0.0    0.0    1.278985       -0.104431   \n",
      "2  1.046254            0.0            0.0    0.0    1.216327       -0.089512   \n",
      "3  0.971661            0.0            0.0    0.0    1.141733       -0.074593   \n",
      "4  0.911986            0.0            0.0    0.0    1.061173       -0.059675   \n",
      "\n",
      "      lag_1     lag_2  \n",
      "0  1.314790  1.344627  \n",
      "1  1.240196  1.314790  \n",
      "2  1.135766  1.240196  \n",
      "3  1.046254  1.135766  \n",
      "4  0.971661  1.046254  \n",
      "Data preprocessing completed and saved to 'preprocessed_combined_data1.csv'\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    xml_files = [\n",
    "        'E:/SEM8/Code/Ohio T1DM/OhioT1DM/2020/test/540-ws-testing.xml',\n",
    "        'E:/SEM8/Code/Ohio T1DM/OhioT1DM/2020/test/552-ws-testing.xml',\n",
    "        'E:/SEM8/Code/Ohio T1DM/OhioT1DM/2020/test/552-ws-testing.xml',\n",
    "        'E:/SEM8/Code/Ohio T1DM/OhioT1DM/2020/test/552-ws-testing.xml',\n",
    "        'E:/SEM8/Code/Ohio T1DM/OhioT1DM/2020/test/552-ws-testing.xml',\n",
    "        'E:/SEM8/Code/Ohio T1DM/OhioT1DM/2020/test/552-ws-testing.xml'\n",
    "        # Add more XML file paths as needed\n",
    "    ]\n",
    "    \n",
    "    combined_data, scaler = process_multiple_xml(xml_files)\n",
    "    \n",
    "    # Display the first few rows of the combined dataset\n",
    "    print(combined_data.head())\n",
    "    \n",
    "    # Save the preprocessed data to a CSV file\n",
    "    combined_data.to_csv('preprocessed_combined_data1.csv', index=False)\n",
    "    \n",
    "    print(\"Data preprocessing completed and saved to 'preprocessed_combined_data1.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
